{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxU2obuYo5VV3EGys1dQum",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jayeshp19/multi-agent-systems/blob/main/parallel_tool_calls_vertex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yqifizmMrN4",
        "outputId": "a6ce4685-9e38-4dff-afdf-191679517918"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/6.2 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --user --quiet google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-xo8PfkNDbj",
        "outputId": "b8b8efe9-2c3c-4fb8-e4c2-01d4260d6d9a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "nCf4ri1fNKLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()\n",
        ""
      ],
      "metadata": {
        "id": "DMHyaT8UNMUC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"tribal-archery-440118-d1\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ],
      "metadata": {
        "id": "R0yg2-KeNQRC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "from vertexai.generative_models import (\n",
        "    FunctionDeclaration,\n",
        "    GenerationConfig,\n",
        "    GenerationResponse,\n",
        "    GenerativeModel,\n",
        "    Part,\n",
        "    Tool,\n",
        ")"
      ],
      "metadata": {
        "id": "4i_UQUZuNmaL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_weather = FunctionDeclaration(\n",
        "    name=\"get_weather\",\n",
        "    description=\"Get weather details for provided location\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"location\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Location to get weather for\",\n",
        "            },\n",
        "        },\n",
        "    },\n",
        ")\n",
        "\n",
        "get_weather_tool = Tool(\n",
        "    function_declarations=[\n",
        "        get_weather,\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "id": "bLKPt6DlNp2X"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GenerativeModel(\n",
        "    \"gemini-1.5-pro\",\n",
        "    generation_config=GenerationConfig(temperature=0),\n",
        "    tools=[get_weather_tool],\n",
        ")"
      ],
      "metadata": {
        "id": "k-w_KodrOv8L"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contents = [\n",
        "  {\"role\": \"model\", \"parts\": [{\"text\": \"You are a weather assistant created by LiveKit. Your interface with users will be voice. You will provide weather information for a given location.\"}]},\n",
        "  {\"role\": \"model\", \"parts\": [{\"text\": \" Hello from the weather station. Would you like to know the weather? If so, tell me your location.\"}]},\n",
        "  {\"role\": \"user\", \"parts\": [{\"text\": \"Mumbai and Delhi.\"}]},\n",
        "  {\"role\": \"model\", \"parts\": [\n",
        "      {\"function_call\": {\"name\": \"get_weather\", \"args\": {\"fields\": [{\"key\": \"location\", \"value\": {\"string_value\": \"Mumbai\"}}]}}},\n",
        "      {\"function_call\": {\"name\": \"get_weather\", \"args\": {\"fields\": [{\"key\": \"location\", \"value\": {\"string_value\": \"Delhi\"}}]}}}\n",
        "  ]},\n",
        "  {\"role\": \"user\", \"parts\": [\n",
        "      {\"function_response\": {\"name\": \"get_weather\", \"response\": {\"fields\": [{\"key\": \"content\", \"value\": {\"string_value\": \"The weather in Mumbai is Haze +28°C.\"}}]}}}\n",
        "  ]},\n",
        "  {\"role\": \"user\", \"parts\": [\n",
        "      {\"function_response\": {\"name\": \"get_weather\", \"response\": {\"fields\": [{\"key\": \"content\", \"value\": {\"string_value\": \"The weather in Delhi is Clear +25°C.\"}}]}}}\n",
        "  ]}\n",
        "]\n",
        "\n",
        "contents_2 = [\n",
        "  {\"role\": \"model\", \"parts\": [{\"text\": \"You are a weather assistant created by LiveKit. Your interface with users will be voice. You will provide weather information for a given location.\"}]},\n",
        "  {\"role\": \"model\", \"parts\": [{\"text\": \" Hello from the weather station. Would you like to know the weather? If so, tell me your location.\"}]},\n",
        "  {\"role\": \"user\", \"parts\": [{\"text\": \"Mumbai and Delhi.\"}]},\n",
        "  {\"role\": \"model\", \"parts\": [\n",
        "      {\"function_call\": {\"name\": \"get_weather\", \"args\": {\"fields\": [{\"key\": \"location\", \"value\": {\"string_value\": \"Mumbai\"}}]}}},\n",
        "      {\"function_call\": {\"name\": \"get_weather\", \"args\": {\"fields\": [{\"key\": \"location\", \"value\": {\"string_value\": \"Delhi\"}}]}}}\n",
        "  ]},\n",
        "  {\"role\": \"user\", \"parts\": [\n",
        "      {\"function_response\": {\"name\": \"get_weather\", \"response\": {\"fields\": [{\"key\": \"content\", \"value\": {\"string_value\": \"The weather in Mumbai is Haze +28°C.\"}}]}}},\n",
        "      {\"function_response\": {\"name\": \"get_weather\", \"response\": {\"fields\": [{\"key\": \"content\", \"value\": {\"string_value\": \"The weather in Delhi is Clear +25°C.\"}}]}}}\n",
        "  ]},\n",
        "]\n",
        "\n",
        "contents_3 = [\n",
        "  {\"role\": \"model\", \"parts\": [{\"text\": \"You are a weather assistant created by LiveKit. Your interface with users will be voice. You will provide weather information for a given location.\"}]},\n",
        "  {\"role\": \"model\", \"parts\": [{\"text\": \" Hello from the weather station. Would you like to know the weather? If so, tell me your location.\"}]},\n",
        "  {\"role\": \"user\", \"parts\": [{\"text\": \"Mumbai and Delhi.\"}]},\n",
        "  {\"role\": \"model\", \"parts\": [\n",
        "      {\"function_call\": {\"name\": \"get_weather\", \"args\": {\"fields\": [{\"key\": \"location\", \"value\": {\"string_value\": \"Mumbai\"}}]}}},\n",
        "  ]},\n",
        "  {\"role\": \"user\", \"parts\": [\n",
        "      {\"function_response\": {\"name\": \"get_weather\", \"response\": {\"fields\": [{\"key\": \"content\", \"value\": {\"string_value\": \"The weather in Mumbai is Haze +28°C.\"}}]}}},\n",
        "  ]},\n",
        "]\n",
        "\n",
        "try:\n",
        "  response = model.generate_content(contents)\n",
        "  print(response)\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "\n",
        "try:\n",
        "  response_2 = model.generate_content(contents_2)\n",
        "  print(response_2)\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "\n",
        "\n",
        "try:\n",
        "  response_3 = model.generate_content(contents_3)\n",
        "  print(response_3)\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNlf6aILO6_k",
        "outputId": "d285c47d-985f-4f6c-8ab7-e45cc126f478"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400 Please ensure that function response turn comes immediately after a function call turn. And the number of function response parts should be equal to number of function call parts of the function call turn.\n",
            "candidates {\n",
            "  content {\n",
            "    role: \"model\"\n",
            "    parts {\n",
            "      text: \"The weather in Mumbai is Haze plus 28 degrees Celsius. The weather in Delhi is Clear plus 25 degrees Celsius. Do you need any other information? \\n\"\n",
            "    }\n",
            "  }\n",
            "  finish_reason: STOP\n",
            "  safety_ratings {\n",
            "    category: HARM_CATEGORY_HATE_SPEECH\n",
            "    probability: NEGLIGIBLE\n",
            "    probability_score: 0.0439453125\n",
            "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
            "    severity_score: 0.053466796875\n",
            "  }\n",
            "  safety_ratings {\n",
            "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
            "    probability: NEGLIGIBLE\n",
            "    probability_score: 0.08251953125\n",
            "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
            "    severity_score: 0.0673828125\n",
            "  }\n",
            "  safety_ratings {\n",
            "    category: HARM_CATEGORY_HARASSMENT\n",
            "    probability: NEGLIGIBLE\n",
            "    probability_score: 0.1083984375\n",
            "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
            "    severity_score: 0.03515625\n",
            "  }\n",
            "  safety_ratings {\n",
            "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
            "    probability: NEGLIGIBLE\n",
            "    probability_score: 0.064453125\n",
            "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
            "    severity_score: 0.1279296875\n",
            "  }\n",
            "  avg_logprobs: -0.016171784060341973\n",
            "}\n",
            "usage_metadata {\n",
            "  prompt_token_count: 135\n",
            "  candidates_token_count: 35\n",
            "  total_token_count: 170\n",
            "}\n",
            "model_version: \"gemini-1.5-pro-001\"\n",
            "\n",
            "candidates {\n",
            "  content {\n",
            "    role: \"model\"\n",
            "    parts {\n",
            "      text: \"The weather in Mumbai is Haze +28\\302\\260C. \\n\"\n",
            "    }\n",
            "    parts {\n",
            "      function_call {\n",
            "        name: \"get_weather\"\n",
            "        args {\n",
            "          fields {\n",
            "            key: \"fields\"\n",
            "            value {\n",
            "              list_value {\n",
            "                values {\n",
            "                  struct_value {\n",
            "                    fields {\n",
            "                      key: \"key\"\n",
            "                      value {\n",
            "                        string_value: \"location\"\n",
            "                      }\n",
            "                    }\n",
            "                    fields {\n",
            "                      key: \"value\"\n",
            "                      value {\n",
            "                        struct_value {\n",
            "                          fields {\n",
            "                            key: \"string_value\"\n",
            "                            value {\n",
            "                              string_value: \"Delhi\"\n",
            "                            }\n",
            "                          }\n",
            "                        }\n",
            "                      }\n",
            "                    }\n",
            "                  }\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  finish_reason: STOP\n",
            "  safety_ratings {\n",
            "    category: HARM_CATEGORY_HATE_SPEECH\n",
            "    probability: NEGLIGIBLE\n",
            "    probability_score: 0.08056640625\n",
            "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
            "    severity_score: 0.06640625\n",
            "  }\n",
            "  safety_ratings {\n",
            "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
            "    probability: NEGLIGIBLE\n",
            "    probability_score: 0.1513671875\n",
            "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
            "    severity_score: 0.140625\n",
            "  }\n",
            "  safety_ratings {\n",
            "    category: HARM_CATEGORY_HARASSMENT\n",
            "    probability: NEGLIGIBLE\n",
            "    probability_score: 0.10986328125\n",
            "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
            "    severity_score: 0.056640625\n",
            "  }\n",
            "  safety_ratings {\n",
            "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
            "    probability: NEGLIGIBLE\n",
            "    probability_score: 0.051025390625\n",
            "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
            "    severity_score: 0.06103515625\n",
            "  }\n",
            "  avg_logprobs: -0.004059719741344452\n",
            "}\n",
            "usage_metadata {\n",
            "  prompt_token_count: 102\n",
            "  candidates_token_count: 25\n",
            "  total_token_count: 127\n",
            "}\n",
            "model_version: \"gemini-1.5-pro-001\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HSdNvncdPCCG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}